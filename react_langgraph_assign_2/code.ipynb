{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c395ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7814493",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    temperature=0.7,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize Web Search\n",
    "web_search = TavilySearchResults(\n",
    "    max_results=3,\n",
    "    api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a09e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[str], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9428f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description=\"selected Topic\")\n",
    "    Reasoning: str = Field(description=\"reasoning for selection\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e30e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base loaded with 10 chunks\n"
     ]
    }
   ],
   "source": [
    "# Load and split knowledge base from usa.txt\n",
    "kb_path = \"usa.txt\"\n",
    "with open(kb_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    kb_text = f.read()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "kb_chunks = [doc.page_content for doc in splitter.create_documents([kb_text])]\n",
    "print(f\"Knowledge base loaded with {len(kb_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af64b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervisor - Routes queries to appropriate node using Pydantic parser\n",
    "def supervisor(state: AgentState):\n",
    "    question = state[\"messages\"][-1]\n",
    "    print(\"Question:\", question)\n",
    "    \n",
    "    template = \"\"\"\n",
    "    Your task is to classify the given user query into one of the following categories: [USA, Web, General]. \n",
    "    \n",
    "    - USA: If the query is about the U.S. economy and can be answered from knowledge base\n",
    "    - Web: If the query needs current/recent information, latest developments, or real-time data\n",
    "    - General: For other general questions that don't need specific knowledge or current info\n",
    "    \n",
    "    User query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"question\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    print(\"Parsed response:\", response)\n",
    "    \n",
    "    return {\"messages\": [response.Topic]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c286a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router function\n",
    "def router(state: AgentState):\n",
    "    print(\"->ROUTER->\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    print(\"last_message:\", last_message)\n",
    "    \n",
    "    if \"usa\" in last_message.lower():\n",
    "        return \"RAG\"\n",
    "    elif \"web\" in last_message.lower():\n",
    "        return \"WEB\" \n",
    "    else:\n",
    "        return \"LLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb7a6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Node - Uses knowledge base chunks\n",
    "def rag_node(state: AgentState):\n",
    "    print(\"->RAG Call->\")\n",
    "    question = state[\"messages\"][0]  # Original question\n",
    "    \n",
    "    # Find relevant chunks\n",
    "    chunks_text = \"\\n\\n\".join([f\"Chunk {i+1}: {chunk}\" for i, chunk in enumerate(kb_chunks)])\n",
    "    \n",
    "    template = \"\"\"Use the following context to answer the question. Answer in natural language paragraph format without markdown, bullets, or headings.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "    response = llm.invoke(prompt.format(context=chunks_text, question=question))\n",
    "    \n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0000122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Node - General questions\n",
    "def llm_node(state: AgentState):\n",
    "    print(\"->LLM Call->\")\n",
    "    question = state[\"messages\"][0]  # Original question\n",
    "    \n",
    "    template = \"\"\"Answer the following question in natural language paragraph format. Do not use markdown, bullet points, or headings.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "    response = llm.invoke(prompt.format(question=question))\n",
    "    \n",
    "    return {\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a06e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Search Node\n",
    "def web_node(state: AgentState):\n",
    "    print(\"->WEB Call->\")\n",
    "    question = state[\"messages\"][0]  # Original question\n",
    "    \n",
    "    try:\n",
    "        results = web_search.invoke({\"query\": question})\n",
    "        search_content = results[0][\"content\"] if results else \"No search results found\"\n",
    "        \n",
    "        template = \"\"\"Based on the web search results, answer the question in natural language paragraph format. Do not use markdown, bullet points, or headings.\n",
    "\n",
    "Search Results: {results}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=template, input_variables=[\"results\", \"question\"])\n",
    "        response = llm.invoke(prompt.format(results=search_content, question=question))\n",
    "        \n",
    "        return {\"messages\": [response.content]}\n",
    "    except Exception as e:\n",
    "        print(f\"Web search failed: {e}\")\n",
    "        return {\"messages\": [\"Unable to perform web search at this time.\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed39c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5958824a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15afb88d000>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"supervisor\", supervisor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a8e1b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15afb88d000>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow.add_node(\"RAG\", rag_node)\n",
    "workflow.add_node(\"LLM\", llm_node)\n",
    "workflow.add_node(\"WEB\", web_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984b59c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15afb88d000>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_entry_point(\"supervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb5bc1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15afb88d000>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    router,\n",
    "    {\n",
    "        \"RAG\": \"RAG\",\n",
    "        \"LLM\": \"LLM\", \n",
    "        \"WEB\": \"WEB\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30cdb4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15afb88d000>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"RAG\", END)\n",
    "workflow.add_edge(\"LLM\", END)\n",
    "workflow.add_edge(\"WEB\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e5a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "021dd698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the key strengths of the U.S. economy?\n",
      "Parsed response: Topic='USA' Reasoning='The query is specifically about the U.S. economy and asks for its key strengths, which is information typically available in a knowledge base about the U.S. economy. It does not require current or real-time data.'\n",
      "->ROUTER->\n",
      "last_message: USA\n",
      "->RAG Call->\n",
      "Parsed response: Topic='USA' Reasoning='The query is specifically about the U.S. economy and asks for its key strengths, which is information typically available in a knowledge base about the U.S. economy. It does not require current or real-time data.'\n",
      "->ROUTER->\n",
      "last_message: USA\n",
      "->RAG Call->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The U.S. economy possesses several key strengths that solidify its position as the world's largest and most powerful. These include a highly flexible labor market, deep and liquid capital markets, and technological superiority underpinned by massive investment in research and development and top-tier universities. A legal system that strongly encourages innovation and protects property rights further supports this dynamic. The U.S. benefits from a large, highly educated workforce, access to vast natural resources, and a diverse immigration pipeline. It is a global innovation hub, home to many of the world's leading companies and a vibrant startup ecosystem, particularly strong in sectors like technology, software, biotechnology, and financial services. The U.S. dollar's status as the global reserve currency provides significant advantages, while robust consumer spending acts as a major driver of economic stability. The economy is also highly diversified across numerous strong sectors and maintains a central role in global economic policy.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1 = {\"messages\": [\"What are the key strengths of the U.S. economy?\"]}\n",
    "result1 = app.invoke(state1)\n",
    "result1[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d663eb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the latest AI developments in 2025?\n",
      "Parsed response: Topic='Web' Reasoning=\"The query asks for the 'latest' developments in AI for the year '2025'. This requires access to current information, recent research, or future predictions, which necessitates searching the web for up-to-date data.\"\n",
      "->ROUTER->\n",
      "last_message: Web\n",
      "->WEB Call->\n",
      "Parsed response: Topic='Web' Reasoning=\"The query asks for the 'latest' developments in AI for the year '2025'. This requires access to current information, recent research, or future predictions, which necessitates searching the web for up-to-date data.\"\n",
      "->ROUTER->\n",
      "last_message: Web\n",
      "->WEB Call->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on reports from 2025, significant developments in AI include Google's announcement of Gemini 2.0, described as their most capable model to date, featuring agentic capabilities for various users. Google also introduced new state-of-the-art AI video and image generation models named Veo 2 and Imagen 3. Concurrently, analysis highlights India and China as key AI innovation hubs, noting an intensifying divide between open-source and closed AI ecosystems and suggesting that collaboration and transparency will influence global AI leadership. China is actively accelerating its AI development, partly to counter trade restrictions, by rolling out models like Manus and DeepSeek to rival top US models, increasing collaboration between government, private sectors, and universities, reducing dependence on imported technology, and establishing a National Computing Power Grid to support these advancements.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2 = {\"messages\": [\"What are the latest AI developments in 2025?\"]}\n",
    "result2 = app.invoke(state2)\n",
    "result2[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "956f33cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Explain how photosynthesis works\n",
      "Parsed response: Topic='General' Reasoning='The query asks for an explanation of a fundamental biological process (photosynthesis), which falls under general scientific knowledge and does not require specific U.S. economy data or current information from the web.'\n",
      "->ROUTER->\n",
      "last_message: General\n",
      "->LLM Call->\n",
      "Parsed response: Topic='General' Reasoning='The query asks for an explanation of a fundamental biological process (photosynthesis), which falls under general scientific knowledge and does not require specific U.S. economy data or current information from the web.'\n",
      "->ROUTER->\n",
      "last_message: General\n",
      "->LLM Call->\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Photosynthesis is the vital process by which plants, algae, and some bacteria convert light energy into chemical energy, essentially creating their own food. This complex process primarily takes place in the chloroplasts, organelles found mainly in the leaves of plants, which contain a green pigment called chlorophyll. The plant takes in three key ingredients from its environment: carbon dioxide from the air, which enters through small pores on the leaves called stomata; water from the soil, absorbed by the roots and transported up to the leaves; and light energy from the sun. Inside the chloroplasts, chlorophyll captures this light energy. Photosynthesis involves two main stages. In the first stage, the light-dependent reactions, light energy is used to split water molecules, producing oxygen as a byproduct and generating energy-carrying molecules. In the second stage, known as the light-independent reactions or Calvin cycle, the energy from the first stage is used to convert carbon dioxide from the air into glucose, a type of sugar. This glucose is the plant's food source; it can be used immediately for energy, stored for later use, or converted into other organic molecules needed for growth and development. The oxygen produced during the light-dependent reactions is released back into the atmosphere through the stomata, which is crucial for the respiration of most living organisms. Therefore, photosynthesis transforms light energy, water, and carbon dioxide into chemical energy stored in glucose and releases oxygen as a valuable byproduct, forming the base of most food chains on Earth.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state3 = {\"messages\": [\"Explain how photosynthesis works\"]}\n",
    "result3 = app.invoke(state3)\n",
    "result3[\"messages\"][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
